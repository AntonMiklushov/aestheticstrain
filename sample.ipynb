{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Средний скор нужен Вам как основной таргет для регрессии.\n",
    "Датасет AVA устроен так, что каждая фотография имеет распределение оценок (сколько раз её оценили на 1, 2, 3 … 10 баллов). Чтобы обучить регрессионную нейросеть, нужно получить одно число, которое отражает “эстетическую привлекательность” снимка. Это число — средняя оценка (mean score)."
   ],
   "id": "2bad1a2b60ed65a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Прочитаем необходимые колонки:",
   "id": "90b966c18c154a25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:23.474589Z",
     "start_time": "2025-12-01T21:51:23.470516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Пути\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\main\\Desktop\\Aesthetics\")  # при необходимости поправьте\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\" / \"AVA\"\n",
    "\n",
    "ava_txt = DATA_ROOT / \"AVA.txt\"\n",
    "\n",
    "train_ls_list = DATA_ROOT / \"aesthetics_image_lists\" / \"generic_ls_train.jpgl\"\n",
    "val_ss_list   = DATA_ROOT / \"aesthetics_image_lists\" / \"generic_ss_train.jpgl\"\n",
    "test_list     = DATA_ROOT / \"aesthetics_image_lists\" / \"generic_test.jpgl\"\n",
    "\n",
    "images_dir = DATA_ROOT / \"images\"\n",
    "\n",
    "print(\"AVA.txt exists:\", ava_txt.exists())\n",
    "print(\"LS train list exists:\", train_ls_list.exists())\n",
    "print(\"SS val list exists:\", val_ss_list.exists())\n",
    "print(\"Test list exists:\", test_list.exists())\n",
    "print(\"Images dir exists:\", images_dir.exists())\n",
    "\n"
   ],
   "id": "47cc7023acced746",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVA.txt exists: True\n",
      "LS train list exists: True\n",
      "SS val list exists: True\n",
      "Test list exists: True\n",
      "Images dir exists: True\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:23.651519Z",
     "start_time": "2025-12-01T21:51:23.492628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Читаем AVA.txt и считаем mean_score\n",
    "\n",
    "cols = [\"image_id\"] + [f\"n_{i}\" for i in range(1, 11)]\n",
    "ava = pd.read_csv(\n",
    "    ava_txt,\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    usecols=range(1, 12),  # со 2-го по 11-й столбец: image_id + n1..n10\n",
    "    names=cols,\n",
    ")\n",
    "\n",
    "vote_cols = [f\"n_{i}\" for i in range(1, 11)]\n",
    "ava[\"n_total\"] = ava[vote_cols].sum(axis=1)\n",
    "\n",
    "# можно (по желанию) отфильтровать изображения с малым числом голосов\n",
    "# ava = ava[ava[\"n_total\"] >= 50].reset_index(drop=True)\n",
    "\n",
    "weights = pd.Series(range(1, 11), index=vote_cols)\n",
    "ava[\"mean_score\"] = (ava[vote_cols] * weights).sum(axis=1) / ava[\"n_total\"]\n",
    "\n",
    "print(ava.head())\n",
    "print(\"Всего строк в AVA:\", len(ava))\n"
   ],
   "id": "4905680416dc699",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_id  n_1  n_2  n_3  n_4  n_5  n_6  n_7  n_8  n_9  n_10  n_total  \\\n",
      "0    953619    0    1    5   17   38   36   15    6    5     1      124   \n",
      "1    953958   10    7   15   26   26   21   10    8    1     2      126   \n",
      "2    954184    0    0    4    8   41   56   10    3    4     0      126   \n",
      "3    954113    0    1    4    6   48   37   23    5    2     2      128   \n",
      "4    953980    0    3    6   15   57   39    6    1    1     1      129   \n",
      "\n",
      "   mean_score  \n",
      "0    5.637097  \n",
      "1    4.698413  \n",
      "2    5.674603  \n",
      "3    5.773438  \n",
      "4    5.209302  \n",
      "Всего строк в AVA: 255530\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:23.834647Z",
     "start_time": "2025-12-01T21:51:23.825677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Читаем списки id для train / val / test\n",
    "\n",
    "train_ls_ids = pd.read_csv(\n",
    "    train_ls_list,\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    usecols=[0],\n",
    "    names=[\"image_id\"],\n",
    ")\n",
    "\n",
    "val_ss_ids = pd.read_csv(\n",
    "    val_ss_list,\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    usecols=[0],\n",
    "    names=[\"image_id\"],\n",
    ")\n",
    "\n",
    "test_ids = pd.read_csv(\n",
    "    test_list,\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    usecols=[0],\n",
    "    names=[\"image_id\"],\n",
    ")\n",
    "\n",
    "print(\"LS train ids:\", train_ls_ids.shape)\n",
    "print(\"SS val ids:\", val_ss_ids.shape)\n",
    "print(\"Test ids:\", test_ids.shape)\n"
   ],
   "id": "bca74461d1b04552",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS train ids: (20000, 1)\n",
      "SS val ids: (2500, 1)\n",
      "Test ids: (20000, 1)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:23.868146Z",
     "start_time": "2025-12-01T21:51:23.844192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Формируем три датафрейма по академичному разбиению\n",
    "\n",
    "train_df = ava[ava[\"image_id\"].isin(train_ls_ids[\"image_id\"])].copy()\n",
    "val_df   = ava[ava[\"image_id\"].isin(val_ss_ids[\"image_id\"])].copy()\n",
    "test_df  = ava[ava[\"image_id\"].isin(test_ids[\"image_id\"])].copy()\n",
    "\n",
    "print(\"Train df:\", train_df.shape)\n",
    "print(\"Val df:\",   val_df.shape)\n",
    "print(\"Test df:\",  test_df.shape)\n"
   ],
   "id": "9f14659502774e4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train df: (19924, 13)\n",
      "Val df: (2495, 13)\n",
      "Test df: (19930, 13)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:23.980163Z",
     "start_time": "2025-12-01T21:51:23.873151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Добавляем пути к изображениям\n",
    "\n",
    "def make_path(img_id: int | str) -> str:\n",
    "    return str(images_dir / f\"{int(img_id)}.jpg\")\n",
    "\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df[\"image_path\"] = df[\"image_id\"].apply(make_path)\n",
    "\n",
    "# Проверим, что хотя бы один путь существует\n",
    "print(train_df[\"image_path\"].iloc[0], \"exists:\", Path(train_df[\"image_path\"].iloc[0]).exists())\n"
   ],
   "id": "d43a4046d297abca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\main\\Desktop\\Aesthetics\\data\\AVA\\images\\953777.jpg exists: True\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:23.987247Z",
     "start_time": "2025-12-01T21:51:23.984167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ],
   "id": "fe89b7ece9325237",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:24.003065Z",
     "start_time": "2025-12-01T21:51:23.999902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"torch.cuda version:\", torch.version.cuda)\n",
    "print(\"device count:\", torch.cuda.device_count())\n"
   ],
   "id": "2957037182ebc852",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0+cu124\n",
      "cuda available: True\n",
      "torch.cuda version: 12.4\n",
      "device count: 1\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:24.019781Z",
     "start_time": "2025-12-01T21:51:24.016774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ],
   "id": "cc5ed77172cefc38",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:24.030395Z",
     "start_time": "2025-12-01T21:51:24.026398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AVARegressionDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform or T.Compose([\n",
    "            T.Resize((256, 256)),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # простая защита от битых файлов\n",
    "        for _ in range(3):  # до 3 попыток\n",
    "            row = self.df.iloc[idx]\n",
    "            img_path = row[\"image_path\"]\n",
    "            target = row[\"mean_score\"]\n",
    "\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img = self.transform(img)\n",
    "                y = torch.tensor(target, dtype=torch.float32)\n",
    "                return img, y\n",
    "            except OSError:\n",
    "                # если картинка битая — берём следующий индекс по кругу\n",
    "                idx = (idx + 1) % len(self.df)\n",
    "\n",
    "        # если трижды не получилось — возвращаем чёрный квадрат, чтобы не падать\n",
    "        img = torch.zeros(3, 224, 224, dtype=torch.float32)\n",
    "        y = torch.tensor(0.0, dtype=torch.float32)\n",
    "        return img, y\n"
   ],
   "id": "594955918e8ed20",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:24.041126Z",
     "start_time": "2025-12-01T21:51:24.035905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 128  # при необходимости можно увеличить/уменьшить\n",
    "\n",
    "train_ds = AVARegressionDataset(train_df)\n",
    "val_ds   = AVARegressionDataset(val_df)\n",
    "test_ds  = AVARegressionDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)\n"
   ],
   "id": "c3128b611e709737",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19924, 2495, 19930)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:24.431715Z",
     "start_time": "2025-12-01T21:51:24.053254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# предобученный ResNet-50\n",
    "base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "in_features = base_model.fc.in_features\n",
    "base_model.fc = nn.Linear(in_features, 1)  # 1 выход для регрессии\n",
    "\n",
    "model = base_model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model\n"
   ],
   "id": "fadb0aad451be410",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:24.480675Z",
     "start_time": "2025-12-01T21:51:24.476658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import amp\n",
    "import numpy as np\n",
    "\n",
    "scaler = amp.GradScaler(device=\"cuda\")  # вместо GradScaler() из torch.cuda.amp\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    mse_losses = []\n",
    "    mae_losses = []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True).unsqueeze(1)  # (B, 1)\n",
    "\n",
    "        # валидации mixed precision тоже не помешает\n",
    "        with amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            preds = model(x)\n",
    "            mse = criterion(preds, y)\n",
    "            mae = torch.mean(torch.abs(preds - y))\n",
    "\n",
    "        mse_losses.append(mse.item())\n",
    "        mae_losses.append(mae.item())\n",
    "\n",
    "    return float(np.mean(mse_losses)), float(np.mean(mae_losses))\n"
   ],
   "id": "fe3b61ff2532470d",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:24.499491Z",
     "start_time": "2025-12-01T21:51:24.494198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    history = []\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            # mixed precision через torch.amp\n",
    "            with amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                preds = model(x)\n",
    "                loss = criterion(preds, y)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        train_mse = running_loss / max(1, n_batches)\n",
    "        val_mse, val_mae = evaluate(model, val_loader)\n",
    "        scheduler.step(val_mse)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d} | \"\n",
    "            f\"train MSE={train_mse:.4f} | \"\n",
    "            f\"val MSE={val_mse:.4f}, val MAE={val_mae:.4f}\"\n",
    "        )\n",
    "\n",
    "        history.append(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_mse\": train_mse,\n",
    "                \"val_mse\": val_mse,\n",
    "                \"val_mae\": val_mae,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return history\n"
   ],
   "id": "c4dae3831e8e0025",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "==========================================\n",
   "id": "4c612e85d59dbd8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:24.526538Z",
     "start_time": "2025-12-01T21:51:24.505496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128  # можно оставить как есть\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,          # ВАЖНО: 0\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,          # ВАЖНО: 0\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,          # ВАЖНО: 0\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "len(train_ds), len(val_ds), len(test_ds)\n"
   ],
   "id": "d843e2729ed4eed5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19924, 2495, 19930)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T21:51:25.726971Z",
     "start_time": "2025-12-01T21:51:24.545652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "print(\"device var:\", device)\n",
    "p = next(model.parameters())\n",
    "print(\"model param device:\", p.device)\n",
    "\n",
    "t0 = time.time()\n",
    "x_cpu, y_cpu = next(iter(train_loader))\n",
    "t1 = time.time()\n",
    "print(\"got batch in\", t1 - t0, \"sec\")\n",
    "print(\"batch before .to:\", x_cpu.device, y_cpu.device)\n",
    "\n",
    "x = x_cpu.to(device)\n",
    "y = y_cpu.to(device)\n",
    "print(\"batch after .to:\", x.device, y.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(x)\n",
    "print(\"preds device:\", preds.device)\n"
   ],
   "id": "199228aa24ea1ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device var: cuda\n",
      "model param device: cuda:0\n",
      "got batch in 1.1392226219177246 sec\n",
      "batch before .to: cpu cpu\n",
      "batch after .to: cuda:0 cuda:0\n",
      "preds device: cuda:0\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:01:29.907793Z",
     "start_time": "2025-12-01T21:51:26.091891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = train_model(model, train_loader, val_loader, epochs=5)\n",
    "\n"
   ],
   "id": "b612070b2cff145a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\main\\Desktop\\Aesthetics\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\main\\Desktop\\Aesthetics\\.venv\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train MSE=3.3122 | val MSE=0.3388, val MAE=0.4611\n",
      "Epoch 02 | train MSE=0.3241 | val MSE=0.2301, val MAE=0.3789\n",
      "Epoch 03 | train MSE=0.2128 | val MSE=0.1599, val MAE=0.3212\n",
      "Epoch 04 | train MSE=0.1095 | val MSE=0.0847, val MAE=0.2297\n",
      "Epoch 05 | train MSE=0.0674 | val MSE=0.0524, val MAE=0.1782\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проводим оценки.",
   "id": "6582d7aa82465b33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:07:14.524737Z",
     "start_time": "2025-12-01T22:04:14.349696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_full(model, loader):\n",
    "    model.eval()\n",
    "    preds_all = []\n",
    "    targets_all = []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        with amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            preds = model(x).squeeze(1).float()\n",
    "\n",
    "        preds_all.append(preds.cpu().numpy())\n",
    "        targets_all.append(y.cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    targets_all = np.concatenate(targets_all)\n",
    "\n",
    "    mse = np.mean((preds_all - targets_all) ** 2)\n",
    "    mae = np.mean(np.abs(preds_all - targets_all))\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    pearson = pearsonr(preds_all, targets_all)[0]\n",
    "    spearman = spearmanr(preds_all, targets_all)[0]\n",
    "\n",
    "    # простое R^2\n",
    "    ss_res = np.sum((preds_all - targets_all) ** 2)\n",
    "    ss_tot = np.sum((targets_all - targets_all.mean()) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "\n",
    "    return {\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"pearson\": pearson,\n",
    "        \"spearman\": spearman,\n",
    "        \"r2\": r2,\n",
    "    }\n",
    "\n",
    "test_metrics = eval_full(model, test_loader)\n",
    "test_metrics\n"
   ],
   "id": "d47d1b90ae60cf7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\main\\Desktop\\Aesthetics\\.venv\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mse': np.float32(0.39050138),\n",
       " 'rmse': np.float32(0.6249011),\n",
       " 'mae': np.float32(0.49264506),\n",
       " 'pearson': np.float32(0.5852297),\n",
       " 'spearman': np.float64(0.5757736827637447),\n",
       " 'r2': np.float32(0.30879843)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T22:09:03.487155Z",
     "start_time": "2025-12-01T22:09:03.382216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "models_dir = Path(\"models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "model_path = models_dir / \"resnet50_ava_regression.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "model_path\n"
   ],
   "id": "afda01a853910508",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('models/resnet50_ava_regression.pt')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
